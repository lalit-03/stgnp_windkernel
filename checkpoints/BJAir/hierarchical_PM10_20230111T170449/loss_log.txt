================ Training Loss (Wed Jan 11 17:04:49 2023) ================
(epoch: 0, iters: 20, time: 0.001, data: 0.504) nll: 15.99105 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.001, data: 0.007) nll: 17.34966 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.001, data: 0.007) nll: 12.17722 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.001, data: 0.008) nll: 13.82772 kl: 0.00000 
(epoch: 2, iters: 100, time: 0.000, data: 0.007) nll: 12.98191 kl: 0.00000 
(epoch: 2, iters: 120, time: 0.001, data: 0.011) nll: 12.68368 kl: 0.00000 
(epoch: 2, iters: 140, time: 0.001, data: 0.006) nll: 13.71144 kl: 0.00000 
(epoch: 3, iters: 160, time: 0.001, data: 0.006) nll: 13.68351 kl: 0.00000 
(epoch: 3, iters: 180, time: 0.001, data: 0.007) nll: 14.09106 kl: 0.00000 
(epoch: 4, iters: 200, time: 0.001, data: 0.006) nll: 13.64161 kl: 0.00000 
(epoch: 4, iters: 220, time: 0.000, data: 0.005) nll: 13.54245 kl: 0.00000 
(epoch: 4, iters: 240, time: 0.000, data: 0.005) nll: 12.69532 kl: 0.00000 
(epoch: 5, iters: 260, time: 0.001, data: 0.342) nll: 13.46418 kl: 0.00000 
(epoch: 5, iters: 280, time: 0.001, data: 0.006) nll: 12.78971 kl: 0.00000 
(epoch: 6, iters: 300, time: 0.001, data: 0.006) nll: 12.92916 kl: 0.00000 
(epoch: 6, iters: 320, time: 0.001, data: 0.006) nll: 17.24193 kl: 0.00006 
(epoch: 7, iters: 340, time: 0.001, data: 0.006) nll: 13.37260 kl: 0.00398 
(epoch: 7, iters: 360, time: 0.000, data: 0.011) nll: 12.37098 kl: 0.17988 
(epoch: 7, iters: 380, time: 0.001, data: 0.005) nll: 13.02200 kl: 0.23638 
(epoch: 8, iters: 400, time: 0.000, data: 0.006) nll: 10.88852 kl: 0.36309 
(epoch: 8, iters: 420, time: 0.001, data: 0.006) nll: 10.01329 kl: 0.40231 
(epoch: 9, iters: 440, time: 0.000, data: 0.007) nll: 9.94055 kl: 0.35898 
(epoch: 9, iters: 460, time: 0.001, data: 0.006) nll: 9.47943 kl: 0.20411 
(epoch: 9, iters: 480, time: 0.001, data: 0.006) nll: 8.40968 kl: 0.30773 
(epoch: 10, iters: 500, time: 0.001, data: 0.376) nll: 9.70008 kl: 0.26898 
(epoch: 10, iters: 520, time: 0.001, data: 0.007) nll: 8.34182 kl: 0.21123 
(epoch: 11, iters: 540, time: 0.001, data: 0.006) nll: 8.98173 kl: 0.34269 
(epoch: 11, iters: 560, time: 0.001, data: 0.006) nll: 9.08645 kl: 0.27482 
(epoch: 12, iters: 580, time: 0.000, data: 0.006) nll: 8.69496 kl: 0.26306 
(epoch: 12, iters: 600, time: 0.001, data: 0.011) nll: 8.69109 kl: 0.35825 
(epoch: 12, iters: 620, time: 0.000, data: 0.006) nll: 7.67575 kl: 0.29843 
(epoch: 13, iters: 640, time: 0.001, data: 0.006) nll: 7.74790 kl: 0.29290 
(epoch: 13, iters: 660, time: 0.001, data: 0.006) nll: 8.43327 kl: 0.36274 
(epoch: 14, iters: 680, time: 0.000, data: 0.007) nll: 7.98967 kl: 0.50588 
(epoch: 14, iters: 700, time: 0.001, data: 0.006) nll: 7.31463 kl: 0.32369 
(epoch: 14, iters: 720, time: 0.001, data: 0.005) nll: 7.18595 kl: 0.43462 
(epoch: 15, iters: 740, time: 0.001, data: 0.357) nll: 7.02624 kl: 0.34797 
(epoch: 15, iters: 760, time: 0.001, data: 0.007) nll: 6.51376 kl: 0.40006 
(epoch: 16, iters: 780, time: 0.001, data: 0.006) nll: 6.65512 kl: 0.37864 
(epoch: 16, iters: 800, time: 0.000, data: 0.006) nll: 7.98452 kl: 0.65605 
(epoch: 17, iters: 820, time: 0.000, data: 0.006) nll: 6.60288 kl: 0.35717 
(epoch: 17, iters: 840, time: 0.001, data: 0.005) nll: 6.88621 kl: 0.52962 
(epoch: 17, iters: 860, time: 0.001, data: 0.007) nll: 5.76136 kl: 0.44041 
(epoch: 18, iters: 880, time: 0.001, data: 0.006) nll: 5.76787 kl: 0.46102 
(epoch: 18, iters: 900, time: 0.000, data: 0.008) nll: 6.01099 kl: 0.42364 
(epoch: 19, iters: 920, time: 0.000, data: 0.006) nll: 5.38428 kl: 0.34784 
(epoch: 19, iters: 940, time: 0.000, data: 0.005) nll: 6.39892 kl: 0.55613 
(epoch: 19, iters: 960, time: 0.000, data: 0.006) nll: 5.65778 kl: 0.53850 
(epoch: 20, iters: 980, time: 0.000, data: 0.403) nll: 5.70215 kl: 0.55580 
(epoch: 20, iters: 1000, time: 0.001, data: 0.005) nll: 5.07903 kl: 0.49078 
(epoch: 21, iters: 1020, time: 0.001, data: 0.005) nll: 6.18024 kl: 0.80090 
(epoch: 21, iters: 1040, time: 0.001, data: 0.005) nll: 5.13764 kl: 0.58854 
(epoch: 22, iters: 1060, time: 0.000, data: 0.006) nll: 5.53146 kl: 0.63271 
(epoch: 22, iters: 1080, time: 0.001, data: 0.005) nll: 4.81041 kl: 0.74688 
(epoch: 22, iters: 1100, time: 0.001, data: 0.006) nll: 5.64816 kl: 0.71161 
(epoch: 23, iters: 1120, time: 0.001, data: 0.007) nll: 4.33028 kl: 0.78506 
(epoch: 23, iters: 1140, time: 0.000, data: 0.006) nll: 4.03000 kl: 0.55209 
(epoch: 24, iters: 1160, time: 0.000, data: 0.005) nll: 5.30347 kl: 0.81977 
(epoch: 24, iters: 1180, time: 0.001, data: 0.005) nll: 4.32915 kl: 0.63801 
(epoch: 24, iters: 1200, time: 0.001, data: 0.005) nll: 5.07988 kl: 1.21628 
(epoch: 25, iters: 1220, time: 0.001, data: 0.368) nll: 4.44493 kl: 0.86147 
(epoch: 25, iters: 1240, time: 0.001, data: 0.006) nll: 4.62337 kl: 1.09398 
(epoch: 26, iters: 1260, time: 0.000, data: 0.006) nll: 4.79791 kl: 1.02647 
(epoch: 26, iters: 1280, time: 0.000, data: 0.006) nll: 3.62245 kl: 0.76105 
(epoch: 27, iters: 1300, time: 0.000, data: 0.006) nll: 4.83435 kl: 1.20910 
(epoch: 27, iters: 1320, time: 0.001, data: 0.002) nll: 3.62516 kl: 0.80685 
(epoch: 27, iters: 1340, time: 0.001, data: 0.006) nll: 4.41632 kl: 1.10518 
(epoch: 28, iters: 1360, time: 0.001, data: 0.005) nll: 3.59279 kl: 1.11882 
(epoch: 28, iters: 1380, time: 0.000, data: 0.006) nll: 2.92186 kl: 1.13426 
(epoch: 29, iters: 1400, time: 0.001, data: 0.005) nll: 4.25028 kl: 1.55775 
(epoch: 29, iters: 1420, time: 0.000, data: 0.007) nll: 3.26666 kl: 1.21134 
(epoch: 29, iters: 1440, time: 0.001, data: 0.006) nll: 2.73363 kl: 1.05860 
(epoch: 30, iters: 1460, time: 0.001, data: 0.334) nll: 3.34217 kl: 1.74339 
(epoch: 30, iters: 1480, time: 0.000, data: 0.006) nll: 3.65043 kl: 1.42050 
(epoch: 31, iters: 1500, time: 0.000, data: 0.004) nll: 2.11018 kl: 1.41567 
(epoch: 31, iters: 1520, time: 0.000, data: 0.006) nll: 2.54704 kl: 1.50539 
(epoch: 32, iters: 1540, time: 0.000, data: 0.005) nll: 2.53516 kl: 1.18546 
(epoch: 32, iters: 1560, time: 0.001, data: 0.008) nll: 3.89769 kl: 1.45136 
(epoch: 32, iters: 1580, time: 0.001, data: 0.006) nll: 2.45423 kl: 1.43451 
(epoch: 33, iters: 1600, time: 0.001, data: 0.007) nll: 2.63614 kl: 1.49754 
(epoch: 33, iters: 1620, time: 0.001, data: 0.006) nll: 3.12580 kl: 1.74854 
(epoch: 34, iters: 1640, time: 0.000, data: 0.006) nll: 3.49785 kl: 1.62388 
(epoch: 34, iters: 1660, time: 0.001, data: 0.005) nll: 2.59347 kl: 1.18541 
(epoch: 34, iters: 1680, time: 0.000, data: 0.006) nll: 2.15219 kl: 1.51725 
(epoch: 35, iters: 1700, time: 0.001, data: 0.330) nll: 3.53840 kl: 1.86550 
(epoch: 35, iters: 1720, time: 0.001, data: 0.008) nll: 2.31348 kl: 1.36093 
(epoch: 36, iters: 1740, time: 0.000, data: 0.007) nll: 3.30191 kl: 1.53570 
(epoch: 36, iters: 1760, time: 0.000, data: 0.005) nll: 3.16111 kl: 1.53897 
(epoch: 37, iters: 1780, time: 0.001, data: 0.007) nll: 3.18873 kl: 1.28475 
(epoch: 37, iters: 1800, time: 0.001, data: 0.008) nll: 2.87046 kl: 1.84555 
(epoch: 37, iters: 1820, time: 0.001, data: 0.006) nll: 2.61172 kl: 1.44303 
(epoch: 38, iters: 1840, time: 0.001, data: 0.006) nll: 1.93310 kl: 1.58595 
(epoch: 38, iters: 1860, time: 0.000, data: 0.006) nll: 2.54580 kl: 1.50618 
(epoch: 39, iters: 1880, time: 0.000, data: 0.007) nll: 2.95034 kl: 1.59348 
(epoch: 39, iters: 1900, time: 0.001, data: 0.005) nll: 2.15661 kl: 1.83707 
(epoch: 39, iters: 1920, time: 0.001, data: 0.006) nll: 2.09077 kl: 1.22322 
(epoch: 40, iters: 1940, time: 0.001, data: 0.374) nll: 2.14149 kl: 1.34963 
(epoch: 40, iters: 1960, time: 0.001, data: 0.006) nll: 1.94075 kl: 1.46333 
(epoch: 41, iters: 1980, time: 0.000, data: 0.006) nll: 1.99316 kl: 1.69483 
(epoch: 41, iters: 2000, time: 0.000, data: 0.006) nll: 2.55175 kl: 1.63926 
(epoch: 42, iters: 2020, time: 0.001, data: 0.006) nll: 2.10966 kl: 1.90820 
(epoch: 42, iters: 2040, time: 0.001, data: 0.005) nll: 1.81129 kl: 1.40863 
(epoch: 42, iters: 2060, time: 0.001, data: 0.005) nll: 1.62632 kl: 1.52871 
(epoch: 43, iters: 2080, time: 0.000, data: 0.006) nll: 1.88801 kl: 1.41416 
(epoch: 43, iters: 2100, time: 0.001, data: 0.007) nll: 2.94223 kl: 1.76008 
(epoch: 44, iters: 2120, time: 0.000, data: 0.006) nll: 1.68362 kl: 1.51465 
(epoch: 44, iters: 2140, time: 0.001, data: 0.006) nll: 2.66390 kl: 1.67698 
(epoch: 44, iters: 2160, time: 0.001, data: 0.006) nll: 2.44976 kl: 1.34940 
(epoch: 45, iters: 2180, time: 0.000, data: 0.414) nll: 2.91113 kl: 1.56622 
(epoch: 45, iters: 2200, time: 0.000, data: 0.005) nll: 3.07783 kl: 1.57958 
(epoch: 46, iters: 2220, time: 0.000, data: 0.006) nll: 2.98477 kl: 1.44661 
(epoch: 46, iters: 2240, time: 0.001, data: 0.006) nll: 2.16185 kl: 1.68672 
(epoch: 47, iters: 2260, time: 0.001, data: 0.006) nll: 2.43290 kl: 1.67558 
(epoch: 47, iters: 2280, time: 0.001, data: 0.014) nll: 3.18158 kl: 1.67823 
(epoch: 47, iters: 2300, time: 0.000, data: 0.005) nll: 2.33558 kl: 1.71830 
(epoch: 48, iters: 2320, time: 0.000, data: 0.005) nll: 1.98356 kl: 1.69407 
(epoch: 48, iters: 2340, time: 0.001, data: 0.006) nll: 2.68252 kl: 1.71460 
(epoch: 49, iters: 2360, time: 0.000, data: 0.006) nll: 1.96508 kl: 1.38965 
(epoch: 49, iters: 2380, time: 0.000, data: 0.005) nll: 3.34078 kl: 1.78761 
(epoch: 49, iters: 2400, time: 0.000, data: 0.006) nll: 2.98617 kl: 1.55413 
(epoch: 50, iters: 2420, time: 0.001, data: 0.371) nll: 3.35892 kl: 1.75226 
(epoch: 50, iters: 2440, time: 0.001, data: 0.006) nll: 2.62214 kl: 1.65766 
================ Training Loss (Wed Jan 11 17:09:10 2023) ================
================ Training Loss (Fri May 26 16:40:12 2023) ================
================ Training Loss (Fri May 26 18:26:11 2023) ================
