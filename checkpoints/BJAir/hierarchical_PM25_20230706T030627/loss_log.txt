================ Training Loss (Thu Jul  6 03:06:27 2023) ================
(epoch: 0, iters: 20, time: 0.002, data: 0.269) nll: 26.98968 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.002, data: 0.008) nll: 24.00928 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.002, data: 0.007) nll: 25.65307 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.002, data: 0.007) nll: 26.20590 kl: 0.00001 
(epoch: 2, iters: 100, time: 0.002, data: 0.007) nll: 23.57981 kl: 0.05932 
(epoch: 2, iters: 120, time: 0.002, data: 0.018) nll: 23.24448 kl: 0.11713 
(epoch: 2, iters: 140, time: 0.002, data: 0.007) nll: 20.76718 kl: 0.35514 
(epoch: 3, iters: 160, time: 0.002, data: 0.007) nll: 19.96349 kl: 0.59110 
(epoch: 3, iters: 180, time: 0.002, data: 0.008) nll: 18.05874 kl: 0.25066 
(epoch: 4, iters: 200, time: 0.002, data: 0.008) nll: 18.79617 kl: 0.48037 
(epoch: 4, iters: 220, time: 0.002, data: 0.006) nll: 19.02806 kl: 0.57152 
(epoch: 4, iters: 240, time: 0.002, data: 0.007) nll: 16.33374 kl: 0.30843 
(epoch: 5, iters: 260, time: 0.002, data: 0.259) nll: 18.60514 kl: 0.67112 
(epoch: 5, iters: 280, time: 0.002, data: 0.006) nll: 15.34146 kl: 0.31239 
(epoch: 6, iters: 300, time: 0.002, data: 0.005) nll: 16.12953 kl: 0.37701 
(epoch: 6, iters: 320, time: 0.002, data: 0.006) nll: 17.84601 kl: 0.47558 
(epoch: 7, iters: 340, time: 0.002, data: 0.007) nll: 15.73468 kl: 0.43078 
(epoch: 7, iters: 360, time: 0.002, data: 0.019) nll: 15.48008 kl: 0.42275 
(epoch: 7, iters: 380, time: 0.002, data: 0.009) nll: 14.68872 kl: 0.41433 
(epoch: 8, iters: 400, time: 0.002, data: 0.009) nll: 14.80711 kl: 0.56051 
(epoch: 8, iters: 420, time: 0.002, data: 0.009) nll: 14.20971 kl: 0.48108 
(epoch: 9, iters: 440, time: 0.002, data: 0.009) nll: 13.51058 kl: 0.40794 
(epoch: 9, iters: 460, time: 0.002, data: 0.006) nll: 15.22425 kl: 0.48497 
(epoch: 9, iters: 480, time: 0.002, data: 0.005) nll: 11.78252 kl: 0.33472 
(epoch: 10, iters: 500, time: 0.002, data: 0.252) nll: 14.30842 kl: 0.92066 
(epoch: 10, iters: 520, time: 0.002, data: 0.006) nll: 12.26669 kl: 0.42605 
(epoch: 11, iters: 540, time: 0.002, data: 0.005) nll: 12.75968 kl: 0.51086 
(epoch: 11, iters: 560, time: 0.002, data: 0.005) nll: 12.90847 kl: 0.79905 
(epoch: 12, iters: 580, time: 0.002, data: 0.005) nll: 12.04159 kl: 0.50468 
(epoch: 12, iters: 600, time: 0.002, data: 0.007) nll: 12.79780 kl: 0.78705 
(epoch: 12, iters: 620, time: 0.002, data: 0.007) nll: 12.00829 kl: 0.71324 
(epoch: 13, iters: 640, time: 0.002, data: 0.007) nll: 11.63494 kl: 0.71730 
(epoch: 13, iters: 660, time: 0.002, data: 0.009) nll: 11.11052 kl: 0.68447 
(epoch: 14, iters: 680, time: 0.002, data: 0.008) nll: 11.06422 kl: 0.60243 
(epoch: 14, iters: 700, time: 0.002, data: 0.007) nll: 10.62839 kl: 0.75389 
(epoch: 14, iters: 720, time: 0.002, data: 0.007) nll: 10.96086 kl: 0.65238 
(epoch: 15, iters: 740, time: 0.002, data: 0.271) nll: 11.14902 kl: 1.15887 
(epoch: 15, iters: 760, time: 0.002, data: 0.009) nll: 9.93795 kl: 0.79662 
(epoch: 16, iters: 780, time: 0.002, data: 0.008) nll: 8.79607 kl: 0.57549 
(epoch: 16, iters: 800, time: 0.002, data: 0.009) nll: 9.22982 kl: 1.14829 
(epoch: 17, iters: 820, time: 0.002, data: 0.010) nll: 8.73886 kl: 0.72447 
(epoch: 17, iters: 840, time: 0.002, data: 0.015) nll: 7.67073 kl: 0.83722 
(epoch: 17, iters: 860, time: 0.002, data: 0.006) nll: 9.86788 kl: 1.31337 
(epoch: 18, iters: 880, time: 0.002, data: 0.009) nll: 7.78563 kl: 0.84739 
(epoch: 18, iters: 900, time: 0.002, data: 0.006) nll: 8.01552 kl: 1.03801 
(epoch: 19, iters: 920, time: 0.002, data: 0.008) nll: 9.06050 kl: 1.22434 
(epoch: 19, iters: 940, time: 0.002, data: 0.007) nll: 7.40858 kl: 0.74517 
(epoch: 19, iters: 960, time: 0.002, data: 0.007) nll: 4.89234 kl: 0.68436 
(epoch: 20, iters: 980, time: 0.002, data: 0.289) nll: 6.67306 kl: 0.71095 
(epoch: 20, iters: 1000, time: 0.002, data: 0.009) nll: 6.47625 kl: 0.97207 
(epoch: 21, iters: 1020, time: 0.002, data: 0.007) nll: 7.29024 kl: 1.34293 
(epoch: 21, iters: 1040, time: 0.002, data: 0.008) nll: 5.62943 kl: 0.93721 
(epoch: 22, iters: 1060, time: 0.002, data: 0.008) nll: 3.73574 kl: 0.97964 
(epoch: 22, iters: 1080, time: 0.002, data: 0.013) nll: 6.85072 kl: 1.67465 
(epoch: 22, iters: 1100, time: 0.002, data: 0.008) nll: 4.76179 kl: 1.92073 
(epoch: 23, iters: 1120, time: 0.002, data: 0.009) nll: 5.67818 kl: 1.72841 
(epoch: 23, iters: 1140, time: 0.002, data: 0.009) nll: 4.17250 kl: 1.27123 
(epoch: 24, iters: 1160, time: 0.002, data: 0.008) nll: 3.13056 kl: 1.74440 
(epoch: 24, iters: 1180, time: 0.002, data: 0.009) nll: 4.69307 kl: 1.87791 
(epoch: 24, iters: 1200, time: 0.002, data: 0.008) nll: 4.01980 kl: 1.63235 
(epoch: 25, iters: 1220, time: 0.002, data: 0.258) nll: 0.93390 kl: 1.43939 
(epoch: 25, iters: 1240, time: 0.002, data: 0.006) nll: 4.18601 kl: 1.86332 
(epoch: 26, iters: 1260, time: 0.002, data: 0.009) nll: 3.79215 kl: 2.49441 
(epoch: 26, iters: 1280, time: 0.002, data: 0.007) nll: 1.57735 kl: 1.23704 
(epoch: 27, iters: 1300, time: 0.002, data: 0.009) nll: 1.47490 kl: 1.41986 
(epoch: 27, iters: 1320, time: 0.002, data: 0.007) nll: 4.07245 kl: 2.47825 
(epoch: 27, iters: 1340, time: 0.002, data: 0.006) nll: 4.07151 kl: 2.70568 
(epoch: 28, iters: 1360, time: 0.002, data: 0.009) nll: 2.13124 kl: 3.10621 
(epoch: 28, iters: 1380, time: 0.002, data: 0.009) nll: 1.75930 kl: 2.15326 
(epoch: 29, iters: 1400, time: 0.002, data: 0.007) nll: 1.45453 kl: 1.76829 
(epoch: 29, iters: 1420, time: 0.002, data: 0.009) nll: 3.00841 kl: 2.34699 
(epoch: 29, iters: 1440, time: 0.002, data: 0.006) nll: 2.99843 kl: 2.38005 
(epoch: 30, iters: 1460, time: 0.002, data: 0.274) nll: 2.94336 kl: 2.25633 
(epoch: 30, iters: 1480, time: 0.002, data: 0.006) nll: 0.68819 kl: 1.72883 
================ Training Loss (Thu Jul  6 03:13:40 2023) ================
