================ Training Loss (Thu Jul  6 03:20:30 2023) ================
(epoch: 0, iters: 20, time: 0.001, data: 0.287) nll: 26.98961 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.001, data: 0.007) nll: 24.00940 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.001, data: 0.008) nll: 25.65320 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.001, data: 0.009) nll: 26.20627 kl: 0.00001 
(epoch: 2, iters: 100, time: 0.001, data: 0.007) nll: 23.61236 kl: 0.04664 
(epoch: 2, iters: 120, time: 0.001, data: 0.014) nll: 23.38541 kl: 0.14388 
(epoch: 2, iters: 140, time: 0.001, data: 0.008) nll: 20.82605 kl: 0.36534 
(epoch: 3, iters: 160, time: 0.001, data: 0.007) nll: 20.02283 kl: 0.50200 
(epoch: 3, iters: 180, time: 0.001, data: 0.008) nll: 18.01900 kl: 0.22262 
(epoch: 4, iters: 200, time: 0.001, data: 0.010) nll: 18.84501 kl: 0.39833 
(epoch: 4, iters: 220, time: 0.001, data: 0.008) nll: 18.93340 kl: 0.49987 
(epoch: 4, iters: 240, time: 0.001, data: 0.007) nll: 16.29788 kl: 0.27805 
(epoch: 5, iters: 260, time: 0.001, data: 0.334) nll: 18.56703 kl: 0.61091 
(epoch: 5, iters: 280, time: 0.001, data: 0.007) nll: 15.30539 kl: 0.27412 
(epoch: 6, iters: 300, time: 0.001, data: 0.008) nll: 16.22993 kl: 0.35039 
(epoch: 6, iters: 320, time: 0.001, data: 0.006) nll: 17.76776 kl: 0.47355 
(epoch: 7, iters: 340, time: 0.001, data: 0.006) nll: 15.59098 kl: 0.41024 
(epoch: 7, iters: 360, time: 0.001, data: 0.015) nll: 15.19345 kl: 0.38622 
(epoch: 7, iters: 380, time: 0.001, data: 0.009) nll: 14.73517 kl: 0.40289 
(epoch: 8, iters: 400, time: 0.001, data: 0.007) nll: 14.53129 kl: 0.54071 
(epoch: 8, iters: 420, time: 0.001, data: 0.007) nll: 14.15550 kl: 0.44966 
(epoch: 9, iters: 440, time: 0.001, data: 0.008) nll: 13.46347 kl: 0.41576 
(epoch: 9, iters: 460, time: 0.001, data: 0.007) nll: 15.01418 kl: 0.49979 
(epoch: 9, iters: 480, time: 0.001, data: 0.007) nll: 11.20504 kl: 0.27462 
(epoch: 10, iters: 500, time: 0.001, data: 0.297) nll: 14.00146 kl: 0.82031 
(epoch: 10, iters: 520, time: 0.001, data: 0.007) nll: 12.83237 kl: 0.39395 
(epoch: 11, iters: 540, time: 0.001, data: 0.010) nll: 13.37979 kl: 0.55845 
(epoch: 11, iters: 560, time: 0.001, data: 0.008) nll: 12.07779 kl: 0.64484 
(epoch: 12, iters: 580, time: 0.001, data: 0.008) nll: 12.47165 kl: 0.59336 
(epoch: 12, iters: 600, time: 0.001, data: 0.020) nll: 12.58272 kl: 0.67206 
(epoch: 12, iters: 620, time: 0.001, data: 0.008) nll: 11.04613 kl: 0.69226 
(epoch: 13, iters: 640, time: 0.001, data: 0.007) nll: 11.80702 kl: 0.71625 
(epoch: 13, iters: 660, time: 0.001, data: 0.007) nll: 10.28932 kl: 0.61892 
(epoch: 14, iters: 680, time: 0.001, data: 0.008) nll: 11.06713 kl: 0.58402 
(epoch: 14, iters: 700, time: 0.001, data: 0.008) nll: 10.76917 kl: 0.86020 
(epoch: 14, iters: 720, time: 0.001, data: 0.009) nll: 9.88236 kl: 0.55256 
(epoch: 15, iters: 740, time: 0.001, data: 0.297) nll: 11.15535 kl: 1.06004 
(epoch: 15, iters: 760, time: 0.001, data: 0.008) nll: 10.02817 kl: 0.81498 
(epoch: 16, iters: 780, time: 0.001, data: 0.008) nll: 7.96361 kl: 0.57944 
(epoch: 16, iters: 800, time: 0.001, data: 0.008) nll: 9.41713 kl: 1.48052 
(epoch: 17, iters: 820, time: 0.001, data: 0.009) nll: 8.40660 kl: 0.72834 
(epoch: 17, iters: 840, time: 0.001, data: 0.011) nll: 7.16885 kl: 0.72668 
(epoch: 17, iters: 860, time: 0.001, data: 0.010) nll: 10.27121 kl: 1.48155 
(epoch: 18, iters: 880, time: 0.001, data: 0.007) nll: 7.92516 kl: 0.97192 
(epoch: 18, iters: 900, time: 0.001, data: 0.009) nll: 8.03805 kl: 0.94552 
(epoch: 19, iters: 920, time: 0.001, data: 0.007) nll: 9.32386 kl: 1.34807 
(epoch: 19, iters: 940, time: 0.001, data: 0.012) nll: 7.24014 kl: 0.69983 
(epoch: 19, iters: 960, time: 0.001, data: 0.007) nll: 4.58575 kl: 0.64144 
(epoch: 20, iters: 980, time: 0.001, data: 0.328) nll: 5.97303 kl: 0.67231 
(epoch: 20, iters: 1000, time: 0.001, data: 0.007) nll: 5.23761 kl: 0.82976 
(epoch: 21, iters: 1020, time: 0.001, data: 0.009) nll: 6.76191 kl: 1.21395 
(epoch: 21, iters: 1040, time: 0.001, data: 0.007) nll: 5.16892 kl: 0.92763 
(epoch: 22, iters: 1060, time: 0.001, data: 0.009) nll: 2.16080 kl: 0.84214 
(epoch: 22, iters: 1080, time: 0.001, data: 0.015) nll: 5.86962 kl: 2.13770 
(epoch: 22, iters: 1100, time: 0.001, data: 0.008) nll: 3.87307 kl: 1.57385 
(epoch: 23, iters: 1120, time: 0.001, data: 0.010) nll: 7.20532 kl: 2.32979 
(epoch: 23, iters: 1140, time: 0.001, data: 0.008) nll: 4.18558 kl: 1.72631 
(epoch: 24, iters: 1160, time: 0.001, data: 0.009) nll: 1.44071 kl: 1.40229 
(epoch: 24, iters: 1180, time: 0.001, data: 0.007) nll: 4.54945 kl: 1.89386 
(epoch: 24, iters: 1200, time: 0.001, data: 0.009) nll: 3.84254 kl: 1.70805 
(epoch: 25, iters: 1220, time: 0.001, data: 0.318) nll: 1.00240 kl: 1.50871 
(epoch: 25, iters: 1240, time: 0.001, data: 0.009) nll: 3.83732 kl: 1.88155 
(epoch: 26, iters: 1260, time: 0.001, data: 0.009) nll: 4.48580 kl: 2.98646 
(epoch: 26, iters: 1280, time: 0.001, data: 0.008) nll: 0.91547 kl: 1.49900 
(epoch: 27, iters: 1300, time: 0.001, data: 0.008) nll: 1.58778 kl: 1.67336 
(epoch: 27, iters: 1320, time: 0.001, data: 0.009) nll: 4.04388 kl: 2.38213 
(epoch: 27, iters: 1340, time: 0.001, data: 0.007) nll: 3.25881 kl: 1.96572 
(epoch: 28, iters: 1360, time: 0.001, data: 0.008) nll: 2.01195 kl: 2.88409 
(epoch: 28, iters: 1380, time: 0.001, data: 0.008) nll: 1.78162 kl: 1.95476 
(epoch: 29, iters: 1400, time: 0.001, data: 0.009) nll: 0.02845 kl: 1.46232 
(epoch: 29, iters: 1420, time: 0.001, data: 0.009) nll: 3.14621 kl: 2.21734 
(epoch: 29, iters: 1440, time: 0.001, data: 0.009) nll: 2.58722 kl: 1.97953 
(epoch: 30, iters: 1460, time: 0.001, data: 0.345) nll: 2.97467 kl: 2.46779 
(epoch: 30, iters: 1480, time: 0.001, data: 0.013) nll: 0.68893 kl: 1.78149 
================ Training Loss (Thu Jul  6 03:23:36 2023) ================
