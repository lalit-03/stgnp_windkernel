================ Training Loss (Thu Jul  6 03:24:46 2023) ================
(epoch: 0, iters: 20, time: 0.001, data: 0.288) nll: 26.98960 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.001, data: 0.007) nll: 24.00940 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.001, data: 0.007) nll: 25.65326 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.001, data: 0.007) nll: 26.20635 kl: 0.00003 
(epoch: 2, iters: 100, time: 0.001, data: 0.008) nll: 23.35453 kl: 0.31529 
(epoch: 2, iters: 120, time: 0.001, data: 0.011) nll: 22.98903 kl: 0.28606 
(epoch: 2, iters: 140, time: 0.001, data: 0.007) nll: 20.33750 kl: 0.37829 
(epoch: 3, iters: 160, time: 0.001, data: 0.007) nll: 20.14202 kl: 0.44327 
(epoch: 3, iters: 180, time: 0.001, data: 0.007) nll: 17.91539 kl: 0.22554 
(epoch: 4, iters: 200, time: 0.001, data: 0.008) nll: 18.75228 kl: 0.42167 
(epoch: 4, iters: 220, time: 0.001, data: 0.008) nll: 18.66148 kl: 0.53117 
(epoch: 4, iters: 240, time: 0.001, data: 0.007) nll: 16.25155 kl: 0.27592 
(epoch: 5, iters: 260, time: 0.001, data: 0.319) nll: 18.46076 kl: 0.54779 
(epoch: 5, iters: 280, time: 0.001, data: 0.008) nll: 15.29403 kl: 0.27917 
(epoch: 6, iters: 300, time: 0.001, data: 0.007) nll: 16.20831 kl: 0.31615 
(epoch: 6, iters: 320, time: 0.001, data: 0.009) nll: 17.49002 kl: 0.48923 
(epoch: 7, iters: 340, time: 0.001, data: 0.011) nll: 15.47042 kl: 0.38107 
(epoch: 7, iters: 360, time: 0.001, data: 0.016) nll: 14.98457 kl: 0.38421 
(epoch: 7, iters: 380, time: 0.001, data: 0.009) nll: 14.60793 kl: 0.42255 
(epoch: 8, iters: 400, time: 0.001, data: 0.006) nll: 14.45389 kl: 0.46105 
(epoch: 8, iters: 420, time: 0.001, data: 0.007) nll: 14.06736 kl: 0.44086 
(epoch: 9, iters: 440, time: 0.001, data: 0.007) nll: 13.36430 kl: 0.41091 
(epoch: 9, iters: 460, time: 0.001, data: 0.008) nll: 14.74903 kl: 0.48273 
(epoch: 9, iters: 480, time: 0.001, data: 0.009) nll: 11.14835 kl: 0.29501 
(epoch: 10, iters: 500, time: 0.001, data: 0.338) nll: 12.93678 kl: 0.77869 
(epoch: 10, iters: 520, time: 0.001, data: 0.008) nll: 11.96517 kl: 0.50005 
(epoch: 11, iters: 540, time: 0.001, data: 0.010) nll: 13.21651 kl: 0.57234 
(epoch: 11, iters: 560, time: 0.001, data: 0.008) nll: 12.50065 kl: 0.63318 
(epoch: 12, iters: 580, time: 0.001, data: 0.008) nll: 12.79489 kl: 0.71440 
(epoch: 12, iters: 600, time: 0.001, data: 0.016) nll: 12.91623 kl: 0.64028 
(epoch: 12, iters: 620, time: 0.001, data: 0.009) nll: 10.95048 kl: 0.67943 
(epoch: 13, iters: 640, time: 0.001, data: 0.008) nll: 11.78980 kl: 0.71737 
(epoch: 13, iters: 660, time: 0.001, data: 0.008) nll: 10.37471 kl: 0.64692 
(epoch: 14, iters: 680, time: 0.001, data: 0.008) nll: 10.89188 kl: 0.56096 
(epoch: 14, iters: 700, time: 0.001, data: 0.008) nll: 10.70576 kl: 0.90726 
(epoch: 14, iters: 720, time: 0.001, data: 0.007) nll: 9.81283 kl: 0.58979 
(epoch: 15, iters: 740, time: 0.001, data: 0.379) nll: 11.16751 kl: 1.08914 
(epoch: 15, iters: 760, time: 0.001, data: 0.008) nll: 9.87836 kl: 0.87796 
(epoch: 16, iters: 780, time: 0.001, data: 0.008) nll: 7.88245 kl: 0.59368 
(epoch: 16, iters: 800, time: 0.001, data: 0.007) nll: 9.35403 kl: 1.49850 
(epoch: 17, iters: 820, time: 0.001, data: 0.007) nll: 8.34732 kl: 0.72850 
(epoch: 17, iters: 840, time: 0.001, data: 0.015) nll: 6.90204 kl: 0.91202 
(epoch: 17, iters: 860, time: 0.001, data: 0.007) nll: 10.29466 kl: 1.44477 
(epoch: 18, iters: 880, time: 0.001, data: 0.007) nll: 7.84692 kl: 1.00009 
(epoch: 18, iters: 900, time: 0.001, data: 0.010) nll: 8.14124 kl: 0.89972 
(epoch: 19, iters: 920, time: 0.001, data: 0.007) nll: 9.51431 kl: 1.38939 
(epoch: 19, iters: 940, time: 0.001, data: 0.007) nll: 7.09710 kl: 0.84563 
(epoch: 19, iters: 960, time: 0.001, data: 0.008) nll: 4.55170 kl: 0.71479 
(epoch: 20, iters: 980, time: 0.001, data: 0.343) nll: 6.17260 kl: 0.67752 
(epoch: 20, iters: 1000, time: 0.001, data: 0.008) nll: 5.65075 kl: 0.86785 
(epoch: 21, iters: 1020, time: 0.001, data: 0.008) nll: 7.23452 kl: 1.12219 
(epoch: 21, iters: 1040, time: 0.001, data: 0.009) nll: 5.48791 kl: 0.99960 
(epoch: 22, iters: 1060, time: 0.001, data: 0.008) nll: 2.16659 kl: 0.98872 
(epoch: 22, iters: 1080, time: 0.001, data: 0.019) nll: 5.72670 kl: 2.35590 
(epoch: 22, iters: 1100, time: 0.001, data: 0.008) nll: 3.74914 kl: 1.58551 
(epoch: 23, iters: 1120, time: 0.001, data: 0.008) nll: 6.57570 kl: 2.39882 
(epoch: 23, iters: 1140, time: 0.001, data: 0.010) nll: 3.63592 kl: 1.65010 
(epoch: 24, iters: 1160, time: 0.001, data: 0.009) nll: 1.48398 kl: 1.51036 
(epoch: 24, iters: 1180, time: 0.001, data: 0.007) nll: 4.83082 kl: 1.95194 
(epoch: 24, iters: 1200, time: 0.001, data: 0.006) nll: 3.72762 kl: 1.81803 
(epoch: 25, iters: 1220, time: 0.001, data: 0.356) nll: 0.96096 kl: 1.56508 
(epoch: 25, iters: 1240, time: 0.001, data: 0.007) nll: 3.81206 kl: 1.95041 
(epoch: 26, iters: 1260, time: 0.001, data: 0.007) nll: 4.33351 kl: 3.11556 
(epoch: 26, iters: 1280, time: 0.001, data: 0.008) nll: 1.01145 kl: 1.52392 
(epoch: 27, iters: 1300, time: 0.001, data: 0.008) nll: 1.60347 kl: 1.71373 
(epoch: 27, iters: 1320, time: 0.001, data: 0.016) nll: 4.26746 kl: 2.35755 
(epoch: 27, iters: 1340, time: 0.001, data: 0.011) nll: 3.29624 kl: 1.95834 
(epoch: 28, iters: 1360, time: 0.001, data: 0.008) nll: 2.01975 kl: 3.21322 
(epoch: 28, iters: 1380, time: 0.001, data: 0.008) nll: 2.00710 kl: 1.85028 
(epoch: 29, iters: 1400, time: 0.001, data: 0.008) nll: 0.05599 kl: 1.50498 
(epoch: 29, iters: 1420, time: 0.001, data: 0.008) nll: 3.16513 kl: 2.31005 
(epoch: 29, iters: 1440, time: 0.001, data: 0.008) nll: 2.66812 kl: 1.96791 
(epoch: 30, iters: 1460, time: 0.001, data: 0.343) nll: 2.94917 kl: 2.55976 
(epoch: 30, iters: 1480, time: 0.001, data: 0.007) nll: 0.72641 kl: 1.81222 
================ Training Loss (Thu Jul  6 03:27:56 2023) ================
