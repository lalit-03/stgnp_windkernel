================ Training Loss (Thu Jul  6 03:32:04 2023) ================
(epoch: 0, iters: 20, time: 0.001, data: 0.289) nll: 26.98965 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.001, data: 0.012) nll: 24.00942 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.001, data: 0.006) nll: 25.65320 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.001, data: 0.008) nll: 26.20644 kl: 0.00000 
(epoch: 2, iters: 100, time: 0.001, data: 0.010) nll: 23.61349 kl: 0.05109 
(epoch: 2, iters: 120, time: 0.001, data: 0.007) nll: 23.27573 kl: 0.26135 
(epoch: 2, iters: 140, time: 0.001, data: 0.007) nll: 21.15759 kl: 0.33694 
(epoch: 3, iters: 160, time: 0.001, data: 0.006) nll: 19.98120 kl: 0.69326 
(epoch: 3, iters: 180, time: 0.001, data: 0.006) nll: 18.18818 kl: 0.23908 
(epoch: 4, iters: 200, time: 0.001, data: 0.007) nll: 18.88199 kl: 0.41060 
(epoch: 4, iters: 220, time: 0.001, data: 0.013) nll: 18.77602 kl: 0.61915 
(epoch: 4, iters: 240, time: 0.001, data: 0.009) nll: 16.36501 kl: 0.29843 
(epoch: 5, iters: 260, time: 0.001, data: 0.329) nll: 18.57644 kl: 0.56981 
(epoch: 5, iters: 280, time: 0.001, data: 0.007) nll: 15.42058 kl: 0.29937 
(epoch: 6, iters: 300, time: 0.001, data: 0.007) nll: 16.26525 kl: 0.32608 
(epoch: 6, iters: 320, time: 0.001, data: 0.008) nll: 17.57009 kl: 0.46467 
(epoch: 7, iters: 340, time: 0.001, data: 0.007) nll: 15.55795 kl: 0.38544 
(epoch: 7, iters: 360, time: 0.001, data: 0.009) nll: 15.22956 kl: 0.38353 
(epoch: 7, iters: 380, time: 0.001, data: 0.010) nll: 14.69228 kl: 0.41342 
(epoch: 8, iters: 400, time: 0.001, data: 0.007) nll: 14.98811 kl: 0.47423 
(epoch: 8, iters: 420, time: 0.001, data: 0.008) nll: 14.16527 kl: 0.43365 
(epoch: 9, iters: 440, time: 0.001, data: 0.007) nll: 13.42425 kl: 0.38333 
(epoch: 9, iters: 460, time: 0.001, data: 0.008) nll: 14.58091 kl: 0.56493 
(epoch: 9, iters: 480, time: 0.001, data: 0.007) nll: 11.63901 kl: 0.30953 
(epoch: 10, iters: 500, time: 0.001, data: 0.301) nll: 13.01467 kl: 0.77428 
(epoch: 10, iters: 520, time: 0.001, data: 0.008) nll: 12.02281 kl: 0.50262 
(epoch: 11, iters: 540, time: 0.001, data: 0.008) nll: 13.22619 kl: 0.59611 
(epoch: 11, iters: 560, time: 0.001, data: 0.008) nll: 12.49063 kl: 0.62612 
(epoch: 12, iters: 580, time: 0.001, data: 0.007) nll: 12.72863 kl: 0.66966 
(epoch: 12, iters: 600, time: 0.001, data: 0.008) nll: 12.94787 kl: 0.59426 
(epoch: 12, iters: 620, time: 0.001, data: 0.008) nll: 11.48366 kl: 0.73132 
(epoch: 13, iters: 640, time: 0.001, data: 0.007) nll: 11.60949 kl: 0.65597 
(epoch: 13, iters: 660, time: 0.001, data: 0.008) nll: 10.15030 kl: 0.58002 
(epoch: 14, iters: 680, time: 0.001, data: 0.009) nll: 11.13816 kl: 0.51199 
(epoch: 14, iters: 700, time: 0.001, data: 0.008) nll: 10.39025 kl: 0.65027 
(epoch: 14, iters: 720, time: 0.001, data: 0.008) nll: 10.00717 kl: 0.57426 
(epoch: 15, iters: 740, time: 0.001, data: 0.331) nll: 11.10956 kl: 1.09734 
(epoch: 15, iters: 760, time: 0.001, data: 0.007) nll: 9.96057 kl: 0.82837 
(epoch: 16, iters: 780, time: 0.001, data: 0.010) nll: 8.09568 kl: 0.55193 
(epoch: 16, iters: 800, time: 0.001, data: 0.009) nll: 9.54038 kl: 1.38134 
(epoch: 17, iters: 820, time: 0.001, data: 0.008) nll: 8.44064 kl: 0.71956 
(epoch: 17, iters: 840, time: 0.001, data: 0.015) nll: 7.02937 kl: 0.92037 
(epoch: 17, iters: 860, time: 0.001, data: 0.008) nll: 10.36126 kl: 1.45687 
(epoch: 18, iters: 880, time: 0.001, data: 0.007) nll: 7.76359 kl: 0.93756 
(epoch: 18, iters: 900, time: 0.001, data: 0.007) nll: 6.74957 kl: 0.91864 
(epoch: 19, iters: 920, time: 0.001, data: 0.008) nll: 8.41843 kl: 1.21083 
(epoch: 19, iters: 940, time: 0.001, data: 0.011) nll: 7.52452 kl: 0.73651 
(epoch: 19, iters: 960, time: 0.001, data: 0.012) nll: 4.62587 kl: 0.66624 
(epoch: 20, iters: 980, time: 0.001, data: 0.376) nll: 5.98836 kl: 0.70655 
(epoch: 20, iters: 1000, time: 0.001, data: 0.008) nll: 5.89361 kl: 0.88336 
(epoch: 21, iters: 1020, time: 0.001, data: 0.008) nll: 7.66556 kl: 1.51398 
(epoch: 21, iters: 1040, time: 0.001, data: 0.007) nll: 5.46715 kl: 0.98063 
(epoch: 22, iters: 1060, time: 0.001, data: 0.008) nll: 1.91708 kl: 0.93752 
(epoch: 22, iters: 1080, time: 0.001, data: 0.015) nll: 5.52524 kl: 2.29673 
(epoch: 22, iters: 1100, time: 0.001, data: 0.007) nll: 3.65763 kl: 1.68329 
(epoch: 23, iters: 1120, time: 0.001, data: 0.008) nll: 5.03937 kl: 2.17526 
(epoch: 23, iters: 1140, time: 0.001, data: 0.007) nll: 3.70685 kl: 1.52491 
(epoch: 24, iters: 1160, time: 0.001, data: 0.008) nll: 1.57292 kl: 1.73780 
(epoch: 24, iters: 1180, time: 0.001, data: 0.008) nll: 4.38080 kl: 1.93522 
(epoch: 24, iters: 1200, time: 0.001, data: 0.008) nll: 4.00664 kl: 1.72162 
(epoch: 25, iters: 1220, time: 0.001, data: 0.334) nll: 1.31322 kl: 1.48786 
(epoch: 25, iters: 1240, time: 0.001, data: 0.007) nll: 4.12856 kl: 1.93629 
(epoch: 26, iters: 1260, time: 0.001, data: 0.007) nll: 4.49556 kl: 2.79806 
(epoch: 26, iters: 1280, time: 0.001, data: 0.008) nll: 1.02460 kl: 1.48602 
(epoch: 27, iters: 1300, time: 0.001, data: 0.006) nll: 1.58992 kl: 1.62931 
(epoch: 27, iters: 1320, time: 0.001, data: 0.007) nll: 4.15842 kl: 2.38793 
(epoch: 27, iters: 1340, time: 0.001, data: 0.009) nll: 3.35808 kl: 2.05628 
(epoch: 28, iters: 1360, time: 0.001, data: 0.008) nll: 2.02998 kl: 3.16060 
(epoch: 28, iters: 1380, time: 0.001, data: 0.008) nll: 2.08933 kl: 1.80518 
(epoch: 29, iters: 1400, time: 0.001, data: 0.008) nll: 0.28754 kl: 1.48436 
(epoch: 29, iters: 1420, time: 0.001, data: 0.008) nll: 3.29928 kl: 2.19135 
(epoch: 29, iters: 1440, time: 0.001, data: 0.007) nll: 2.91535 kl: 1.94014 
(epoch: 30, iters: 1460, time: 0.001, data: 0.327) nll: 2.96239 kl: 2.52796 
(epoch: 30, iters: 1480, time: 0.001, data: 0.008) nll: 0.85368 kl: 1.80099 
================ Training Loss (Thu Jul  6 03:35:12 2023) ================
