================ Training Loss (Thu Jul  6 03:40:43 2023) ================
(epoch: 0, iters: 20, time: 0.001, data: 0.305) nll: 26.98965 kl: 0.00000 
(epoch: 0, iters: 40, time: 0.001, data: 0.007) nll: 24.00942 kl: 0.00000 
(epoch: 1, iters: 60, time: 0.001, data: 0.008) nll: 25.65319 kl: 0.00000 
(epoch: 1, iters: 80, time: 0.001, data: 0.008) nll: 26.20656 kl: 0.00001 
(epoch: 2, iters: 100, time: 0.001, data: 0.007) nll: 23.59851 kl: 0.07011 
(epoch: 2, iters: 120, time: 0.001, data: 0.007) nll: 23.24850 kl: 0.27730 
(epoch: 2, iters: 140, time: 0.001, data: 0.007) nll: 20.97194 kl: 0.33053 
(epoch: 3, iters: 160, time: 0.001, data: 0.010) nll: 20.05277 kl: 0.57570 
(epoch: 3, iters: 180, time: 0.001, data: 0.008) nll: 18.09068 kl: 0.23631 
(epoch: 4, iters: 200, time: 0.001, data: 0.011) nll: 18.83124 kl: 0.43530 
(epoch: 4, iters: 220, time: 0.001, data: 0.007) nll: 18.71069 kl: 0.65622 
(epoch: 4, iters: 240, time: 0.001, data: 0.008) nll: 16.35075 kl: 0.31152 
(epoch: 5, iters: 260, time: 0.001, data: 0.388) nll: 18.45259 kl: 0.63229 
(epoch: 5, iters: 280, time: 0.001, data: 0.012) nll: 15.30085 kl: 0.31631 
(epoch: 6, iters: 300, time: 0.001, data: 0.007) nll: 16.15326 kl: 0.39665 
(epoch: 6, iters: 320, time: 0.001, data: 0.007) nll: 17.47769 kl: 0.52737 
(epoch: 7, iters: 340, time: 0.001, data: 0.008) nll: 15.44258 kl: 0.48050 
(epoch: 7, iters: 360, time: 0.001, data: 0.019) nll: 15.19551 kl: 0.42574 
(epoch: 7, iters: 380, time: 0.001, data: 0.007) nll: 14.68210 kl: 0.42057 
(epoch: 8, iters: 400, time: 0.001, data: 0.007) nll: 14.89264 kl: 0.54695 
(epoch: 8, iters: 420, time: 0.001, data: 0.008) nll: 14.17024 kl: 0.42427 
(epoch: 9, iters: 440, time: 0.001, data: 0.008) nll: 13.42999 kl: 0.38112 
(epoch: 9, iters: 460, time: 0.001, data: 0.011) nll: 14.66844 kl: 0.55428 
(epoch: 9, iters: 480, time: 0.001, data: 0.007) nll: 11.65204 kl: 0.32123 
(epoch: 10, iters: 500, time: 0.001, data: 0.359) nll: 13.04051 kl: 0.73136 
(epoch: 10, iters: 520, time: 0.001, data: 0.007) nll: 12.02475 kl: 0.47986 
(epoch: 11, iters: 540, time: 0.001, data: 0.008) nll: 13.24886 kl: 0.56623 
(epoch: 11, iters: 560, time: 0.001, data: 0.007) nll: 12.59356 kl: 0.59686 
(epoch: 12, iters: 580, time: 0.001, data: 0.007) nll: 12.85075 kl: 0.62088 
(epoch: 12, iters: 600, time: 0.001, data: 0.011) nll: 12.78375 kl: 0.67849 
(epoch: 12, iters: 620, time: 0.001, data: 0.008) nll: 11.49641 kl: 0.72771 
(epoch: 13, iters: 640, time: 0.001, data: 0.008) nll: 11.64136 kl: 0.68880 
(epoch: 13, iters: 660, time: 0.001, data: 0.007) nll: 10.15520 kl: 0.60112 
(epoch: 14, iters: 680, time: 0.001, data: 0.007) nll: 11.15508 kl: 0.49390 
(epoch: 14, iters: 700, time: 0.001, data: 0.007) nll: 10.41470 kl: 0.64375 
(epoch: 14, iters: 720, time: 0.001, data: 0.007) nll: 9.98169 kl: 0.55233 
(epoch: 15, iters: 740, time: 0.001, data: 0.347) nll: 11.06859 kl: 1.16208 
(epoch: 15, iters: 760, time: 0.001, data: 0.007) nll: 10.00659 kl: 0.85490 
(epoch: 16, iters: 780, time: 0.001, data: 0.006) nll: 8.03747 kl: 0.56715 
(epoch: 16, iters: 800, time: 0.001, data: 0.009) nll: 9.42995 kl: 1.46599 
(epoch: 17, iters: 820, time: 0.001, data: 0.007) nll: 8.39380 kl: 0.68804 
(epoch: 17, iters: 840, time: 0.001, data: 0.012) nll: 6.99712 kl: 0.89135 
(epoch: 17, iters: 860, time: 0.001, data: 0.006) nll: 10.34632 kl: 1.54393 
(epoch: 18, iters: 880, time: 0.001, data: 0.006) nll: 7.82488 kl: 0.89130 
(epoch: 18, iters: 900, time: 0.001, data: 0.010) nll: 6.65942 kl: 0.93049 
(epoch: 19, iters: 920, time: 0.001, data: 0.008) nll: 8.20909 kl: 1.20751 
(epoch: 19, iters: 940, time: 0.001, data: 0.008) nll: 7.26972 kl: 0.69442 
(epoch: 19, iters: 960, time: 0.001, data: 0.007) nll: 4.55908 kl: 0.64705 
(epoch: 20, iters: 980, time: 0.001, data: 0.366) nll: 5.98888 kl: 0.72603 
(epoch: 20, iters: 1000, time: 0.001, data: 0.007) nll: 5.96821 kl: 0.90385 
(epoch: 21, iters: 1020, time: 0.001, data: 0.011) nll: 7.34455 kl: 1.72830 
(epoch: 21, iters: 1040, time: 0.001, data: 0.010) nll: 5.11157 kl: 0.96338 
(epoch: 22, iters: 1060, time: 0.001, data: 0.009) nll: 1.81459 kl: 0.95186 
(epoch: 22, iters: 1080, time: 0.001, data: 0.009) nll: 5.42346 kl: 2.38031 
(epoch: 22, iters: 1100, time: 0.001, data: 0.007) nll: 3.45901 kl: 1.71935 
(epoch: 23, iters: 1120, time: 0.001, data: 0.008) nll: 4.88656 kl: 2.47530 
(epoch: 23, iters: 1140, time: 0.001, data: 0.006) nll: 3.65017 kl: 1.63318 
(epoch: 24, iters: 1160, time: 0.001, data: 0.007) nll: 1.41986 kl: 1.49510 
(epoch: 24, iters: 1180, time: 0.001, data: 0.007) nll: 4.09571 kl: 2.12902 
(epoch: 24, iters: 1200, time: 0.001, data: 0.007) nll: 3.94921 kl: 1.77012 
(epoch: 25, iters: 1220, time: 0.001, data: 0.380) nll: 1.15217 kl: 1.53992 
(epoch: 25, iters: 1240, time: 0.001, data: 0.007) nll: 3.95987 kl: 1.92603 
(epoch: 26, iters: 1260, time: 0.001, data: 0.008) nll: 4.39830 kl: 3.02615 
(epoch: 26, iters: 1280, time: 0.001, data: 0.008) nll: 0.78483 kl: 1.60015 
(epoch: 27, iters: 1300, time: 0.001, data: 0.007) nll: 1.60818 kl: 1.65219 
(epoch: 27, iters: 1320, time: 0.001, data: 0.008) nll: 4.29137 kl: 2.33766 
(epoch: 27, iters: 1340, time: 0.001, data: 0.008) nll: 3.25547 kl: 2.06429 
(epoch: 28, iters: 1360, time: 0.001, data: 0.008) nll: 2.08636 kl: 3.30737 
(epoch: 28, iters: 1380, time: 0.001, data: 0.005) nll: 2.04446 kl: 1.87558 
(epoch: 29, iters: 1400, time: 0.001, data: 0.009) nll: 0.32930 kl: 1.50189 
(epoch: 29, iters: 1420, time: 0.001, data: 0.011) nll: 3.20604 kl: 2.21120 
(epoch: 29, iters: 1440, time: 0.001, data: 0.008) nll: 2.85433 kl: 2.05679 
(epoch: 30, iters: 1460, time: 0.001, data: 0.367) nll: 3.00477 kl: 2.56693 
(epoch: 30, iters: 1480, time: 0.001, data: 0.007) nll: 0.74056 kl: 1.83692 
================ Training Loss (Thu Jul  6 03:43:50 2023) ================
